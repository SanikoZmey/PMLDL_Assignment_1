{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `In some places code can be simplified/removed/replaced`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all necessary packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "from datasets import Dataset\n",
    "from transformers import (AutoTokenizer, DataCollatorForSeq2Seq, AutoModelForSeq2SeqLM, \n",
    "                          Seq2SeqTrainingArguments, Seq2SeqTrainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I'm not gonna have a child... ...with the same...</td>\n",
       "      <td>I'm not going to breed kids with a genetic dis...</td>\n",
       "      <td>0.703185</td>\n",
       "      <td>0.206522</td>\n",
       "      <td>0.950956</td>\n",
       "      <td>0.035846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>They're all laughing at us, so we'll kick your...</td>\n",
       "      <td>they're laughing at us. We'll show you.</td>\n",
       "      <td>0.618866</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.999492</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Maine was very short on black people back then.</td>\n",
       "      <td>there wasn't much black in Maine then.</td>\n",
       "      <td>0.720482</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.963680</td>\n",
       "      <td>0.148710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>So now their spirits are cursed, walking back ...</td>\n",
       "      <td>their souls are cursed, they guard the paths, ...</td>\n",
       "      <td>0.755883</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.842509</td>\n",
       "      <td>0.143992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Come on, Cal, leave that shit alone.</td>\n",
       "      <td>come on, Cal, put it down.</td>\n",
       "      <td>0.660481</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.999637</td>\n",
       "      <td>0.000279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            reference  \\\n",
       "5   I'm not gonna have a child... ...with the same...   \n",
       "6   They're all laughing at us, so we'll kick your...   \n",
       "7     Maine was very short on black people back then.   \n",
       "11  So now their spirits are cursed, walking back ...   \n",
       "13               Come on, Cal, leave that shit alone.   \n",
       "\n",
       "                                          translation  similarity  \\\n",
       "5   I'm not going to breed kids with a genetic dis...    0.703185   \n",
       "6             they're laughing at us. We'll show you.    0.618866   \n",
       "7              there wasn't much black in Maine then.    0.720482   \n",
       "11  their souls are cursed, they guard the paths, ...    0.755883   \n",
       "13                         come on, Cal, put it down.    0.660481   \n",
       "\n",
       "    lenght_diff   ref_tox   trn_tox  \n",
       "5      0.206522  0.950956  0.035846  \n",
       "6      0.230769  0.999492  0.000131  \n",
       "7      0.187500  0.963680  0.148710  \n",
       "11     0.013245  0.842509  0.143992  \n",
       "13     0.270270  0.999637  0.000279  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/raw/filtered.tsv\", sep=\"\\t\")\n",
    "toxic = df[df['ref_tox'] > df['trn_tox']].iloc[:, 1:]   # Choosing the partition where the toxicity score of the reference is bigger than the one of its translation\n",
    "toxic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling an example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you don't stop laughing, you'll end up dead... just like your idiot hyena cousins!\n",
      "if you don't stop laughing, you come as your cousins of hyenas.\n"
     ]
    }
   ],
   "source": [
    "print(toxic['reference'].values[100])\n",
    "print(toxic['translation'].values[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking only a part of data with references & their translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sins = toxic[[\"reference\", 'translation']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here it is possible to configure the partition of data that will be taken from all samples for traing(was useful for \"fast check\" of the training process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_factor = sins.shape[0]\n",
    "# part_factor = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the maximum lenght of the toxic sentence for model generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens_r = sins[:part_factor]['reference'].str.lower().str.split().apply(lambda x: len(x))\n",
    "lens_t = sins[:part_factor]['translation'].str.lower().str.split().apply(lambda x: len(x))\n",
    "max_len = np.max([lens_r.max(), lens_t.max()])\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dataset to use .map() method for preparing data for the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(sins[:part_factor]).train_test_split(test_size=0.2)   # Create dataset and split it on \"train\" and \"test\" parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and tokenizer, tokenizing data, creating model and data collator objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6bd73365b2945aca7e4a225a9abfb0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/255313 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cfcebfe990d453d978ef32179e86273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/63829 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint = \"t5-small\" # Model to load - \"T5-small\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)   # Creating tokenizer\n",
    "\n",
    "# Function for preprocessing sentences\n",
    "def preprocess_function(data):\n",
    "    inputs = [sent.lower().split() for sent in data[\"reference\"]]\n",
    "    targets = [sent.lower().split() for sent in data[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, text_target=targets, max_length=max_len, truncation=True, is_split_into_words=True)\n",
    "\n",
    "    return model_inputs\n",
    "\n",
    "# Tokenizing the data in the dataset\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Creating a model's object\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
    "\n",
    "# Creating a data collator's object\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for calculating BLEU score metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ario\\AppData\\Local\\Temp\\ipykernel_27328\\3858898384.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"sacrebleu\")\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"sacrebleu\")\n",
    "\n",
    "# Function for preprocessing data for calculating metrics\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "    return preds, labels\n",
    "\n",
    "# Main function for calculating metrics: BLEU score and average lenght of generated sentences\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    \n",
    "    preds = np.where(preds != -100, preds, tokenizer.pad_token_id)  # Replacing -100 tokens(if any) on pad tokens of the tokenizer\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True) # Decoding tokens to words\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)   # Replacing -100 tokens(if any) on pad tokens of the tokenizer\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True) # Decoding tokens to words\n",
    "    \n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels) # Prepare sentences for calculating metrics\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)   # Calculating BLEU score for each sentence\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]  \n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)    # Calculating average lenght of generated sentences \n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing training hyperparameters and configuring training process with consequent launching it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed77fe62f90646f79a0d089717b68cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79790 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0181, 'learning_rate': 1.987542298533651e-05, 'epoch': 0.06}\n",
      "{'loss': 1.8386, 'learning_rate': 1.975009399674145e-05, 'epoch': 0.13}\n",
      "{'loss': 1.7833, 'learning_rate': 1.9624765008146387e-05, 'epoch': 0.19}\n",
      "{'loss': 1.7439, 'learning_rate': 1.9499436019551323e-05, 'epoch': 0.25}\n",
      "{'loss': 1.7236, 'learning_rate': 1.9374107030956263e-05, 'epoch': 0.31}\n",
      "{'loss': 1.7051, 'learning_rate': 1.92487780423612e-05, 'epoch': 0.38}\n",
      "{'loss': 1.7026, 'learning_rate': 1.912369971174333e-05, 'epoch': 0.44}\n",
      "{'loss': 1.6885, 'learning_rate': 1.8998370723148265e-05, 'epoch': 0.5}\n",
      "{'loss': 1.6686, 'learning_rate': 1.8873041734553205e-05, 'epoch': 0.56}\n",
      "{'loss': 1.6598, 'learning_rate': 1.8747712745958142e-05, 'epoch': 0.63}\n",
      "{'loss': 1.6543, 'learning_rate': 1.862238375736308e-05, 'epoch': 0.69}\n",
      "{'loss': 1.6467, 'learning_rate': 1.8497054768768018e-05, 'epoch': 0.75}\n",
      "{'loss': 1.6412, 'learning_rate': 1.8371725780172955e-05, 'epoch': 0.81}\n",
      "{'loss': 1.6379, 'learning_rate': 1.8246396791577894e-05, 'epoch': 0.88}\n",
      "{'loss': 1.6237, 'learning_rate': 1.812106780298283e-05, 'epoch': 0.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4bb2723ccf04f04bf27aa91408796a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1995 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.493385672569275, 'eval_bleu': 28.7427, 'eval_gen_len': 16.3043, 'eval_runtime': 2547.2054, 'eval_samples_per_second': 25.058, 'eval_steps_per_second': 0.783, 'epoch': 1.0}\n",
      "{'loss': 1.6316, 'learning_rate': 1.7995738814387767e-05, 'epoch': 1.0}\n",
      "{'loss': 1.6065, 'learning_rate': 1.7870660483769897e-05, 'epoch': 1.07}\n",
      "{'loss': 1.6049, 'learning_rate': 1.7745331495174837e-05, 'epoch': 1.13}\n",
      "{'loss': 1.6093, 'learning_rate': 1.7620002506579773e-05, 'epoch': 1.19}\n",
      "{'loss': 1.6169, 'learning_rate': 1.749467351798471e-05, 'epoch': 1.25}\n",
      "{'loss': 1.6062, 'learning_rate': 1.736934452938965e-05, 'epoch': 1.32}\n",
      "{'loss': 1.606, 'learning_rate': 1.7244015540794586e-05, 'epoch': 1.38}\n",
      "{'loss': 1.5861, 'learning_rate': 1.7118937210176715e-05, 'epoch': 1.44}\n",
      "{'loss': 1.5889, 'learning_rate': 1.6993608221581652e-05, 'epoch': 1.5}\n",
      "{'loss': 1.5837, 'learning_rate': 1.6868279232986592e-05, 'epoch': 1.57}\n",
      "{'loss': 1.5847, 'learning_rate': 1.6742950244391528e-05, 'epoch': 1.63}\n",
      "{'loss': 1.5753, 'learning_rate': 1.6617621255796468e-05, 'epoch': 1.69}\n",
      "{'loss': 1.581, 'learning_rate': 1.6492542925178598e-05, 'epoch': 1.75}\n",
      "{'loss': 1.5848, 'learning_rate': 1.6367213936583534e-05, 'epoch': 1.82}\n",
      "{'loss': 1.5838, 'learning_rate': 1.624188494798847e-05, 'epoch': 1.88}\n",
      "{'loss': 1.5649, 'learning_rate': 1.611655595939341e-05, 'epoch': 1.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c6b3a6c61c45889d5da27472c3b971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1995 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4485167264938354, 'eval_bleu': 29.1851, 'eval_gen_len': 16.2659, 'eval_runtime': 2693.1319, 'eval_samples_per_second': 23.701, 'eval_steps_per_second': 0.741, 'epoch': 2.0}\n",
      "{'loss': 1.5726, 'learning_rate': 1.5991477628775536e-05, 'epoch': 2.01}\n",
      "{'loss': 1.5619, 'learning_rate': 1.5866148640180473e-05, 'epoch': 2.07}\n",
      "{'loss': 1.5497, 'learning_rate': 1.5741070309562602e-05, 'epoch': 2.13}\n",
      "{'loss': 1.5601, 'learning_rate': 1.5615741320967542e-05, 'epoch': 2.19}\n",
      "{'loss': 1.5471, 'learning_rate': 1.549041233237248e-05, 'epoch': 2.26}\n",
      "{'loss': 1.5544, 'learning_rate': 1.5365083343777415e-05, 'epoch': 2.32}\n",
      "{'loss': 1.5678, 'learning_rate': 1.5239754355182355e-05, 'epoch': 2.38}\n",
      "{'loss': 1.5409, 'learning_rate': 1.5114425366587293e-05, 'epoch': 2.44}\n",
      "{'loss': 1.5606, 'learning_rate': 1.4989096377992231e-05, 'epoch': 2.51}\n",
      "{'loss': 1.5546, 'learning_rate': 1.4863767389397168e-05, 'epoch': 2.57}\n",
      "{'loss': 1.5486, 'learning_rate': 1.4738438400802106e-05, 'epoch': 2.63}\n",
      "{'loss': 1.5428, 'learning_rate': 1.4613109412207044e-05, 'epoch': 2.69}\n",
      "{'loss': 1.5404, 'learning_rate': 1.4488031081589174e-05, 'epoch': 2.76}\n",
      "{'loss': 1.5447, 'learning_rate': 1.436270209299411e-05, 'epoch': 2.82}\n",
      "{'loss': 1.5515, 'learning_rate': 1.4237373104399048e-05, 'epoch': 2.88}\n",
      "{'loss': 1.5355, 'learning_rate': 1.4112044115803987e-05, 'epoch': 2.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe353c95e43e4c56b7b696a6e032538f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1995 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.424839735031128, 'eval_bleu': 29.5602, 'eval_gen_len': 16.2472, 'eval_runtime': 2809.5533, 'eval_samples_per_second': 22.719, 'eval_steps_per_second': 0.71, 'epoch': 3.0}\n",
      "{'loss': 1.5322, 'learning_rate': 1.3986965785186116e-05, 'epoch': 3.01}\n",
      "{'loss': 1.5252, 'learning_rate': 1.3861636796591054e-05, 'epoch': 3.07}\n",
      "{'loss': 1.5327, 'learning_rate': 1.373630780799599e-05, 'epoch': 3.13}\n",
      "{'loss': 1.5401, 'learning_rate': 1.3610978819400929e-05, 'epoch': 3.2}\n",
      "{'loss': 1.5239, 'learning_rate': 1.3485649830805867e-05, 'epoch': 3.26}\n",
      "{'loss': 1.5178, 'learning_rate': 1.3360320842210805e-05, 'epoch': 3.32}\n",
      "{'loss': 1.5273, 'learning_rate': 1.3234991853615742e-05, 'epoch': 3.38}\n",
      "{'loss': 1.5289, 'learning_rate': 1.310966286502068e-05, 'epoch': 3.45}\n",
      "{'loss': 1.5153, 'learning_rate': 1.298433387642562e-05, 'epoch': 3.51}\n",
      "{'loss': 1.5208, 'learning_rate': 1.2859004887830558e-05, 'epoch': 3.57}\n",
      "{'loss': 1.5185, 'learning_rate': 1.2733675899235494e-05, 'epoch': 3.63}\n",
      "{'loss': 1.5154, 'learning_rate': 1.2608346910640432e-05, 'epoch': 3.7}\n",
      "{'loss': 1.5187, 'learning_rate': 1.248301792204537e-05, 'epoch': 3.76}\n",
      "{'loss': 1.5338, 'learning_rate': 1.2357688933450307e-05, 'epoch': 3.82}\n",
      "{'loss': 1.5179, 'learning_rate': 1.2232610602832435e-05, 'epoch': 3.89}\n",
      "{'loss': 1.5163, 'learning_rate': 1.2107281614237375e-05, 'epoch': 3.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232b110efb0b409bbd9eb95bbabbf376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1995 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4082581996917725, 'eval_bleu': 29.6821, 'eval_gen_len': 16.2147, 'eval_runtime': 2816.1135, 'eval_samples_per_second': 22.666, 'eval_steps_per_second': 0.708, 'epoch': 4.0}\n",
      "{'loss': 1.5251, 'learning_rate': 1.1981952625642313e-05, 'epoch': 4.01}\n",
      "{'loss': 1.5069, 'learning_rate': 1.1856623637047251e-05, 'epoch': 4.07}\n",
      "{'loss': 1.5092, 'learning_rate': 1.1731545306429377e-05, 'epoch': 4.14}\n",
      "{'loss': 1.5136, 'learning_rate': 1.1606216317834315e-05, 'epoch': 4.2}\n",
      "{'loss': 1.5252, 'learning_rate': 1.1480887329239253e-05, 'epoch': 4.26}\n",
      "{'loss': 1.5017, 'learning_rate': 1.1355558340644193e-05, 'epoch': 4.32}\n",
      "{'loss': 1.5064, 'learning_rate': 1.123022935204913e-05, 'epoch': 4.39}\n",
      "{'loss': 1.5047, 'learning_rate': 1.1105151021431258e-05, 'epoch': 4.45}\n",
      "{'loss': 1.5049, 'learning_rate': 1.0979822032836196e-05, 'epoch': 4.51}\n",
      "{'loss': 1.4827, 'learning_rate': 1.0854493044241134e-05, 'epoch': 4.57}\n",
      "{'loss': 1.5033, 'learning_rate': 1.072916405564607e-05, 'epoch': 4.64}\n",
      "{'loss': 1.5128, 'learning_rate': 1.0603835067051009e-05, 'epoch': 4.7}\n",
      "{'loss': 1.4964, 'learning_rate': 1.0478756736433138e-05, 'epoch': 4.76}\n",
      "{'loss': 1.5064, 'learning_rate': 1.0353427747838076e-05, 'epoch': 4.83}\n",
      "{'loss': 1.4945, 'learning_rate': 1.0228098759243014e-05, 'epoch': 4.89}\n",
      "{'loss': 1.5028, 'learning_rate': 1.0102769770647951e-05, 'epoch': 4.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a080fbe8c84e15ade72e60dc145c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1995 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3975569009780884, 'eval_bleu': 30.0868, 'eval_gen_len': 16.2677, 'eval_runtime': 2812.3094, 'eval_samples_per_second': 22.696, 'eval_steps_per_second': 0.709, 'epoch': 5.0}\n",
      "{'loss': 1.4909, 'learning_rate': 9.97794209800727e-06, 'epoch': 5.01}\n",
      "{'loss': 1.5038, 'learning_rate': 9.852613109412208e-06, 'epoch': 5.08}\n",
      "{'loss': 1.4966, 'learning_rate': 9.727284120817145e-06, 'epoch': 5.14}\n",
      "{'loss': 1.4964, 'learning_rate': 9.601955132222084e-06, 'epoch': 5.2}\n",
      "{'loss': 1.4945, 'learning_rate': 9.476626143627021e-06, 'epoch': 5.26}\n",
      "{'loss': 1.4969, 'learning_rate': 9.351297155031959e-06, 'epoch': 5.33}\n",
      "{'loss': 1.5042, 'learning_rate': 9.225968166436897e-06, 'epoch': 5.39}\n",
      "{'loss': 1.4878, 'learning_rate': 9.100639177841835e-06, 'epoch': 5.45}\n",
      "{'loss': 1.4803, 'learning_rate': 8.975310189246774e-06, 'epoch': 5.51}\n",
      "{'loss': 1.4755, 'learning_rate': 8.850231858628901e-06, 'epoch': 5.58}\n",
      "{'loss': 1.4887, 'learning_rate': 8.72490287003384e-06, 'epoch': 5.64}\n",
      "{'loss': 1.5035, 'learning_rate': 8.599573881438778e-06, 'epoch': 5.7}\n",
      "{'loss': 1.4829, 'learning_rate': 8.474495550820905e-06, 'epoch': 5.77}\n",
      "{'loss': 1.483, 'learning_rate': 8.349166562225844e-06, 'epoch': 5.83}\n",
      "{'loss': 1.4808, 'learning_rate': 8.224088231607971e-06, 'epoch': 5.89}\n",
      "{'loss': 1.4945, 'learning_rate': 8.09875924301291e-06, 'epoch': 5.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25edc3e4f18843d188fa1404bc564c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1995 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3895801305770874, 'eval_bleu': 30.1083, 'eval_gen_len': 16.2335, 'eval_runtime': 2700.7207, 'eval_samples_per_second': 23.634, 'eval_steps_per_second': 0.739, 'epoch': 6.0}\n",
      "{'loss': 1.4897, 'learning_rate': 7.973430254417848e-06, 'epoch': 6.02}\n",
      "{'loss': 1.4743, 'learning_rate': 7.848101265822786e-06, 'epoch': 6.08}\n",
      "{'loss': 1.4763, 'learning_rate': 7.722772277227724e-06, 'epoch': 6.14}\n",
      "{'loss': 1.4912, 'learning_rate': 7.597443288632661e-06, 'epoch': 6.2}\n",
      "{'loss': 1.4794, 'learning_rate': 7.4721143000375996e-06, 'epoch': 6.27}\n",
      "{'loss': 1.4792, 'learning_rate': 7.346785311442537e-06, 'epoch': 6.33}\n",
      "{'loss': 1.4801, 'learning_rate': 7.221456322847475e-06, 'epoch': 6.39}\n",
      "{'loss': 1.4888, 'learning_rate': 7.096127334252413e-06, 'epoch': 6.45}\n",
      "{'loss': 1.4865, 'learning_rate': 6.970798345657351e-06, 'epoch': 6.52}\n",
      "{'loss': 1.4843, 'learning_rate': 6.845469357062289e-06, 'epoch': 6.58}\n",
      "{'loss': 1.4715, 'learning_rate': 6.720391026444417e-06, 'epoch': 6.64}\n",
      "{'loss': 1.4684, 'learning_rate': 6.595062037849355e-06, 'epoch': 6.71}\n",
      "{'loss': 1.4882, 'learning_rate': 6.469733049254293e-06, 'epoch': 6.77}\n",
      "{'loss': 1.4783, 'learning_rate': 6.34440406065923e-06, 'epoch': 6.83}\n",
      "{'loss': 1.4761, 'learning_rate': 6.219325730041359e-06, 'epoch': 6.89}\n",
      "{'loss': 1.4913, 'learning_rate': 6.093996741446298e-06, 'epoch': 6.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b79011931f0b4e8f990f31b53ddac2e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1995 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3839020729064941, 'eval_bleu': 30.199, 'eval_gen_len': 16.2308, 'eval_runtime': 2813.5709, 'eval_samples_per_second': 22.686, 'eval_steps_per_second': 0.709, 'epoch': 7.0}\n",
      "{'loss': 1.4772, 'learning_rate': 5.968667752851235e-06, 'epoch': 7.02}\n",
      "{'loss': 1.485, 'learning_rate': 5.843338764256173e-06, 'epoch': 7.08}\n",
      "{'loss': 1.4785, 'learning_rate': 5.718009775661111e-06, 'epoch': 7.14}\n",
      "{'loss': 1.4679, 'learning_rate': 5.59268078706605e-06, 'epoch': 7.21}\n",
      "{'loss': 1.4683, 'learning_rate': 5.467351798470987e-06, 'epoch': 7.27}\n",
      "{'loss': 1.462, 'learning_rate': 5.3422734678531156e-06, 'epoch': 7.33}\n",
      "{'loss': 1.4802, 'learning_rate': 5.216944479258053e-06, 'epoch': 7.39}\n",
      "{'loss': 1.4826, 'learning_rate': 5.091615490662991e-06, 'epoch': 7.46}\n",
      "{'loss': 1.4645, 'learning_rate': 4.966286502067928e-06, 'epoch': 7.52}\n",
      "{'loss': 1.4817, 'learning_rate': 4.8409575134728666e-06, 'epoch': 7.58}\n",
      "{'loss': 1.4616, 'learning_rate': 4.715628524877805e-06, 'epoch': 7.65}\n",
      "{'loss': 1.464, 'learning_rate': 4.590299536282742e-06, 'epoch': 7.71}\n",
      "{'loss': 1.4758, 'learning_rate': 4.46497054768768e-06, 'epoch': 7.77}\n",
      "{'loss': 1.4738, 'learning_rate': 4.339641559092618e-06, 'epoch': 7.83}\n",
      "{'loss': 1.4728, 'learning_rate': 4.214563228474747e-06, 'epoch': 7.9}\n",
      "{'loss': 1.4867, 'learning_rate': 4.089234239879684e-06, 'epoch': 7.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efeaa0a0048e44b9a4d2e6d86482bd5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1995 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3794429302215576, 'eval_bleu': 30.2507, 'eval_gen_len': 16.2425, 'eval_runtime': 2876.0606, 'eval_samples_per_second': 22.193, 'eval_steps_per_second': 0.694, 'epoch': 8.0}\n",
      "{'loss': 1.4795, 'learning_rate': 3.9639052512846225e-06, 'epoch': 8.02}\n",
      "{'loss': 1.4637, 'learning_rate': 3.83882692066675e-06, 'epoch': 8.08}\n",
      "{'loss': 1.473, 'learning_rate': 3.7134979320716884e-06, 'epoch': 8.15}\n",
      "{'loss': 1.4729, 'learning_rate': 3.5881689434766266e-06, 'epoch': 8.21}\n",
      "{'loss': 1.468, 'learning_rate': 3.4628399548815644e-06, 'epoch': 8.27}\n",
      "{'loss': 1.4652, 'learning_rate': 3.3375109662865025e-06, 'epoch': 8.33}\n",
      "{'loss': 1.4666, 'learning_rate': 3.2121819776914403e-06, 'epoch': 8.4}\n",
      "{'loss': 1.4792, 'learning_rate': 3.0868529890963785e-06, 'epoch': 8.46}\n",
      "{'loss': 1.4684, 'learning_rate': 2.961524000501316e-06, 'epoch': 8.52}\n",
      "{'loss': 1.4676, 'learning_rate': 2.8361950119062544e-06, 'epoch': 8.59}\n",
      "{'loss': 1.4683, 'learning_rate': 2.711116681288382e-06, 'epoch': 8.65}\n",
      "{'loss': 1.4709, 'learning_rate': 2.58578769269332e-06, 'epoch': 8.71}\n",
      "{'loss': 1.4612, 'learning_rate': 2.460458704098258e-06, 'epoch': 8.77}\n",
      "{'loss': 1.461, 'learning_rate': 2.335129715503196e-06, 'epoch': 8.84}\n",
      "{'loss': 1.4787, 'learning_rate': 2.210051384885324e-06, 'epoch': 8.9}\n",
      "{'loss': 1.477, 'learning_rate': 2.084722396290262e-06, 'epoch': 8.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3cfd7e1a454af28a4e837071b3534b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1995 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.377905011177063, 'eval_bleu': 30.2792, 'eval_gen_len': 16.194, 'eval_runtime': 2716.4888, 'eval_samples_per_second': 23.497, 'eval_steps_per_second': 0.734, 'epoch': 9.0}\n",
      "{'loss': 1.468, 'learning_rate': 1.9593934076952e-06, 'epoch': 9.02}\n",
      "{'loss': 1.4739, 'learning_rate': 1.834064419100138e-06, 'epoch': 9.09}\n",
      "{'loss': 1.4561, 'learning_rate': 1.708735430505076e-06, 'epoch': 9.15}\n",
      "{'loss': 1.4717, 'learning_rate': 1.583406441910014e-06, 'epoch': 9.21}\n",
      "{'loss': 1.4597, 'learning_rate': 1.458077453314952e-06, 'epoch': 9.27}\n",
      "{'loss': 1.4724, 'learning_rate': 1.3329991226970797e-06, 'epoch': 9.34}\n",
      "{'loss': 1.4575, 'learning_rate': 1.207920792079208e-06, 'epoch': 9.4}\n",
      "{'loss': 1.4627, 'learning_rate': 1.0825918034841459e-06, 'epoch': 9.46}\n",
      "{'loss': 1.4617, 'learning_rate': 9.572628148890838e-07, 'epoch': 9.53}\n",
      "{'loss': 1.4635, 'learning_rate': 8.319338262940219e-07, 'epoch': 9.59}\n",
      "{'loss': 1.4666, 'learning_rate': 7.066048376989598e-07, 'epoch': 9.65}\n",
      "{'loss': 1.4647, 'learning_rate': 5.812758491038978e-07, 'epoch': 9.71}\n",
      "{'loss': 1.4804, 'learning_rate': 4.5594686050883577e-07, 'epoch': 9.78}\n",
      "{'loss': 1.4623, 'learning_rate': 3.3061787191377373e-07, 'epoch': 9.84}\n",
      "{'loss': 1.4799, 'learning_rate': 2.0528888331871164e-07, 'epoch': 9.9}\n",
      "{'loss': 1.4594, 'learning_rate': 7.995989472364958e-08, 'epoch': 9.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8beebf01a1e04c34ba8bd7c91be75b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1995 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3774222135543823, 'eval_bleu': 30.3103, 'eval_gen_len': 16.216, 'eval_runtime': 2770.9514, 'eval_samples_per_second': 23.035, 'eval_steps_per_second': 0.72, 'epoch': 10.0}\n",
      "{'train_runtime': 44320.725, 'train_samples_per_second': 57.606, 'train_steps_per_second': 1.8, 'train_loss': 1.5262058627621873, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=79790, training_loss=1.5262058627621873, metrics={'train_runtime': 44320.725, 'train_samples_per_second': 57.606, 'train_steps_per_second': 1.8, 'train_loss': 1.5262058627621873, 'epoch': 10.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = '../models/T5-small_2e-5_32_10_MaxTokenLength' # Path for models checkpoints\n",
    "\n",
    "# All training arguments/hyperparameters\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=new_model,\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=10,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    generation_max_length = max_len + 5,\n",
    "    weight_decay=1e-6,\n",
    ")\n",
    "\n",
    "# Trainer object creation\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Starting training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model checkpoint and generating detoxified sentence\n",
    "    I hope that there is no need to comment anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = AutoModelForSeq2SeqLM.from_pretrained(\"../models/T5-small_detox/final_checkpoint/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(\"Are we going to bring these self-pissing dogs here?\".lower().split(),\n",
    "                      max_length=max_len, truncation=True, is_split_into_words=True, return_tensors=\"pt\").input_ids\n",
    "outputs = test_model.generate(input_ids, max_new_tokens=max_len + 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are we going to bring these dogs here?\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
